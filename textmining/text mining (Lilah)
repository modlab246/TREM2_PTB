###part1 

from Bio import Entrez, Medline
import time
import sys
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Font
import os

def truncate_sheet_name(name, max_length= 31):
    return name if len(name) <= max_length else name[:max_length]

def search_pubmed(genes_proteins):
    Entrez.email = #insert email
    Entrez.api_key = #insert API Key
    all_records = {}
    counts = {}

###part2 github    
    
    for item in genes_proteins:
        item_clean = item.replace('\u200b', '')
        combined_query = f'(tuberculosis[Title/Abstract]) AND ((antimicrobial[Title/Abstract]) OR (kill[Title/Abstract])) AND ({item_clean}[Title/Abstract])'
        print(f"Searching for: {combined_query}")

###Batch Processing & Rate Limiting:
Searches and downloads results for multiple genes in batch mode, with built-in delay to comply with NCBI API usage policies.

        try:
            handle = Entrez.esearch(db="pubmed", term=combined_query, retmax=5000)
            record = Entrez.read(handle)
            handle.close()
        except Exception as e:
            print(f"Error with {item}: {e}")
            continue

        id_list = record.get("IdList", [])
        count = int(record.get("Count", "0"))
        print(f"Found {count} articles for '{item_clean}'.")

        if id_list:
            try:
                fetch_handle = Entrez.efetch(db="pubmed", id=id_list, rettype="medline", retmode="text")
                records = list(Medline.parse(fetch_handle))
                fetch_handle.close()
            except Exception as e:
                print(f"Fetch error for {item}: {e}")
                continue

            filtered_records = []
            for r in records:
                abstract = r.get('AB', '').lower()
                if not any(term in abstract for term in ["in vitro", "serum"]):
                    filtered_records.append(r)

            all_records[item_clean] = filtered_records
            counts[item_clean] = len(filtered_records)
        else:
            print(f"No articles found for '{item_clean}'.")
            all_records[item_clean] = []
            counts[item_clean] = 0

        time.sleep(1)

    return all_records, counts

###part3 github

def create_dataframes(records):
    dataframes = {}
    for item, item_records in records.items():
        data = []
        for record in item_records:
            doi = "N/A"
            if 'AID' in record:
                aids = record['AID']
                doi = next((aid.split(' ')[0] for aid in aids if 'doi' in aid), "N/A")
            doi_url = f"https://doi.org/{doi}" if doi != "N/A" else "No DOI available"

            data.append({
                'PMID': record.get('PMID', 'N/A'),
                'Title': record.get('TI', 'No title available.'),
                'Authors': '; '.join(record.get('AU', ['No authors listed.'])),
                'Journal': record.get('JT', 'No journal available.'),
                'Abstract': record.get('AB', 'No abstract available.'),
                'DOI URL': doi_url
            })
        dataframes[item] = pd.DataFrame(data)
    return dataframes


#part4 github

def save_to_excel(dataframes, filename, counts):
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        summary_df = pd.DataFrame([
            {"Gene/Protein": k, "Article Count": v}
            for k, v in counts.items()
        ])
        summary_df_sorted = summary_df.sort_values(by="Article Count", ascending=False)
        summary_df_sorted.to_excel(writer, sheet_name="Summary", index=False)

        for item, df in dataframes.items():
            sheet_name = truncate_sheet_name(item.split(" OR ")[0])
            df.to_excel(writer, sheet_name=sheet_name, index=False)

    workbook = load_workbook(filename)
    for sheet in workbook.sheetnames:
        worksheet = workbook[sheet]
        for cell in worksheet[1]:
            cell.font = Font(bold=True)

        if sheet != "Summary":
            doi_col_idx = None
            for col in worksheet.iter_cols(1, worksheet.max_column):
                if col[0].value == 'DOI URL':
                    doi_col_idx = col[0].column
                    break
            if doi_col_idx:
                for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=doi_col_idx, max_col=doi_col_idx):
                    cell = row[0]
                    if cell.value and cell.value != "No DOI available":
                        cell.hyperlink = cell.value
                        cell.style = 'Hyperlink'

    workbook.save(filename)
    print(f"\n Results saved to: {os.path.abspath(filename)}")


###part5 github

if __name__ == "__main__":
    genes_proteins = [
###insert gene/protein names from DAVID ]

 try:
        results, counts = search_pubmed(genes_proteins)
        dataframes = create_dataframes(results)
        save_to_excel(dataframes, "pubmed_antimicrobial_gene_results.xlsx", counts)
    except KeyboardInterrupt:
        print("Interrupted by user.")
        sys.exit(0)
    except Exception as e:
        print(f"Unexpected error: {e}")
        sys.exit(1)
